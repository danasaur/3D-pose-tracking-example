{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import cv_utils.core as cv_utils\n",
    "import cv_datetime_utils.core as cv_datetime_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pose_tracking_3d\n",
    "import simplejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output files\n",
    "data_directory = \"./data\"\n",
    "input_dataframe_filename = \"example_2d_poses_dataframe.pickle.xz\"\n",
    "output_dataframe_filename = \"example_3d_pose_tracks_dataframe.pickle.xz\"\n",
    "\n",
    "input_dataframe_path = os.path.join(data_directory, input_dataframe_filename)\n",
    "\n",
    "output_dataframe_path = os.path.join(data_directory, output_dataframe_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "\n",
    "room_size = np.array([7.0, 8.0, 3.0])\n",
    "\n",
    "pose_initialization_model = pose_tracking_3d.PoseInitializationModel(\n",
    "    initial_keypoint_position_means=np.tile(room_size / 2, (18, 1)),\n",
    "    initial_keypoint_velocity_means=np.zeros((18, 3)),\n",
    "    initial_keypoint_position_error=np.amax(room_size) / 2.0,\n",
    "    initial_keypoint_velocity_error=2.0,\n",
    ")\n",
    "\n",
    "keypoint_model = pose_tracking_3d.KeypointModel(\n",
    "    position_observation_error=1.0,\n",
    "    reference_delta_t=0.1,\n",
    "    reference_position_transition_error=0.1,\n",
    "    reference_velocity_transition_error=0.1,\n",
    ")\n",
    "\n",
    "pose_tracking_model = pose_tracking_3d.PoseTrackingModel(\n",
    "    cost_threshold=1.0, num_missed_observations_threshold=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest data\n",
    "input_dataframe = pd.read_pickle(input_dataframe_path)\n",
    "\n",
    "num_rows = input_dataframe.shape[0]\n",
    "\n",
    "camera_names = input_dataframe.columns.levels[0].tolist()\n",
    "\n",
    "camera_calibration_parameters = cv_utils.fetch_camera_calibration_data_from_local_drive_multiple_cameras(\n",
    "    camera_names=camera_names, camera_calibration_data_directory=\"./data\"\n",
    ")\n",
    "\n",
    "initial_dataframe_row = input_dataframe.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poses</th>\n",
       "      <th>file</th>\n",
       "      <th>model</th>\n",
       "      <th>frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-04 18:20:00.000</th>\n",
       "      <td>[[[1098.0, 216.58696, 0.81464326], [1164.0, 24...</td>\n",
       "      <td>video_2018-07-04-18-20-00.mp4</td>\n",
       "      <td>cmu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-04 18:20:00.100</th>\n",
       "      <td>[[[1092.0, 221.86957, 0.92140007], [1158.0, 25...</td>\n",
       "      <td>video_2018-07-04-18-20-00.mp4</td>\n",
       "      <td>cmu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-04 18:20:00.200</th>\n",
       "      <td>[[[1086.0, 227.15218, 0.8493447], [1152.0, 253...</td>\n",
       "      <td>video_2018-07-04-18-20-00.mp4</td>\n",
       "      <td>cmu</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-04 18:20:00.300</th>\n",
       "      <td>[[[1074.0, 227.15218, 0.74878925], [1140.0, 25...</td>\n",
       "      <td>video_2018-07-04-18-20-00.mp4</td>\n",
       "      <td>cmu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-04 18:20:00.400</th>\n",
       "      <td>[[[924.0, 47.54348, 0.9911146], [954.0, 100.36...</td>\n",
       "      <td>video_2018-07-04-18-20-00.mp4</td>\n",
       "      <td>cmu</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     poses  \\\n",
       "2018-07-04 18:20:00.000  [[[1098.0, 216.58696, 0.81464326], [1164.0, 24...   \n",
       "2018-07-04 18:20:00.100  [[[1092.0, 221.86957, 0.92140007], [1158.0, 25...   \n",
       "2018-07-04 18:20:00.200  [[[1086.0, 227.15218, 0.8493447], [1152.0, 253...   \n",
       "2018-07-04 18:20:00.300  [[[1074.0, 227.15218, 0.74878925], [1140.0, 25...   \n",
       "2018-07-04 18:20:00.400  [[[924.0, 47.54348, 0.9911146], [954.0, 100.36...   \n",
       "\n",
       "                                                  file model  frame  \n",
       "2018-07-04 18:20:00.000  video_2018-07-04-18-20-00.mp4   cmu      0  \n",
       "2018-07-04 18:20:00.100  video_2018-07-04-18-20-00.mp4   cmu      1  \n",
       "2018-07-04 18:20:00.200  video_2018-07-04-18-20-00.mp4   cmu      2  \n",
       "2018-07-04 18:20:00.300  video_2018-07-04-18-20-00.mp4   cmu      3  \n",
       "2018-07-04 18:20:00.400  video_2018-07-04-18-20-00.mp4   cmu      4  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dataframe['camera01'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "camera01  poses    [[[1098.0, 216.58696, 0.81464326], [1164.0, 24...\n",
       "          file                         video_2018-07-04-18-20-00.mp4\n",
       "          model                                                  cmu\n",
       "          frame                                                    0\n",
       "camera02  poses    [[[618.0, 10.565217, 0.40926868], [618.0, 26.4...\n",
       "          file                         video_2018-07-04-18-20-00.mp4\n",
       "          model                                                  cmu\n",
       "          frame                                                    0\n",
       "camera03  poses    [[[1104.0, 105.652176, 0.8920398], [1134.0, 15...\n",
       "          file                         video_2018-07-04-18-20-00.mp4\n",
       "          model                                                  cmu\n",
       "          frame                                                    0\n",
       "camera04  poses    [[[618.0, 63.391304, 0.84008336], [612.0, 95.0...\n",
       "          file                         video_2018-07-04-18-20-00.mp4\n",
       "          model                                                  cmu\n",
       "          frame                                                    0\n",
       "Name: 2018-07-04 18:20:00, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# poses from the first millisecond frame from 4 cameras\n",
    "initial_dataframe_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare 2D reconstruction data to be consumed by 3D reconstruction process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert 2D reconstruction data into a 2D poses class object\n",
    "# input data is a dataframe including a set of keypoints poses \n",
    "# reduced to one frame, the first millisecond from 4 cameras\n",
    "\n",
    "initial_poses_2d = pose_tracking_3d.Poses2D.from_dataframe_row(\n",
    "    dataframe_row=initial_dataframe_row, camera_names=camera_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pose_tracking_3d.core.Poses2D at 0x12f7d3490>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a 2D poses class object \n",
    "# contains a list of 2D pose class objects in the \"pose_2d_list_list\" attribute\n",
    "# for one timestamp - the first millisecond of camera data for all 4 cameras\n",
    "initial_poses_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<pose_tracking_3d.core.Pose2D at 0x12f567590>,\n",
       "  <pose_tracking_3d.core.Pose2D at 0x12f56eb10>,\n",
       "  <pose_tracking_3d.core.Pose2D at 0x12f56e290>],\n",
       " [<pose_tracking_3d.core.Pose2D at 0x12f56e7d0>,\n",
       "  <pose_tracking_3d.core.Pose2D at 0x12f56e610>,\n",
       "  <pose_tracking_3d.core.Pose2D at 0x12f565710>],\n",
       " [<pose_tracking_3d.core.Pose2D at 0x12f61c590>,\n",
       "  <pose_tracking_3d.core.Pose2D at 0x12f61c110>,\n",
       "  <pose_tracking_3d.core.Pose2D at 0x12f61c0d0>,\n",
       "  <pose_tracking_3d.core.Pose2D at 0x12f61c190>],\n",
       " [<pose_tracking_3d.core.Pose2D at 0x10e15a310>,\n",
       "  <pose_tracking_3d.core.Pose2D at 0x12c460e10>,\n",
       "  <pose_tracking_3d.core.Pose2D at 0x12c460390>,\n",
       "  <pose_tracking_3d.core.Pose2D at 0x12c4602d0>]]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each pose is a 2D pose class object\n",
    "# for each camera, there is a list of poses found - \n",
    "# in this example, the first two cameras pick up 3 people (poses)\n",
    "# while camera 3 and 4 pick up 4 people (poses)\n",
    "initial_poses_2d.pose_2d_list_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 2)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each 2D pose object has a keypoints attribute with 18 keypoints\n",
    "# a keypoint has one set of x and y values which are pixel coordinates\n",
    "# from the camera image\n",
    "initial_poses_2d.pose_2d_list_list[0][0].keypoints.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D reconstruction using initial 2D poses from first millisecond of data from 4 cameras \n",
    "\n",
    "initial_poses_3d = pose_tracking_3d.Poses3D.from_poses_2d(\n",
    "    poses_2d=initial_poses_2d, cameras=camera_calibration_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<pose_tracking_3d.core.Pose3D at 0x12f686a10>,\n",
       "  <pose_tracking_3d.core.Pose3D at 0x12f60ff90>,\n",
       "  <pose_tracking_3d.core.Pose3D at 0x12f685050>]]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a Poses3d object\n",
    "# 3 unique poses were identified\n",
    "# Dropped the 4th poses found by cameras 3 and 4 \n",
    "# were not considered \"best matches\"\n",
    "# why is this a nested list? When would you have more than one set of 3D poses?\n",
    "initial_poses_3d.pose_3d_list_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pose_tracking_3d.core.Pose3D at 0x12f686a10>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a Pose3D object\n",
    "initial_poses_3d.pose_3d_list_list[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D Pose Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attributes of a 3D pose object:\n",
    "\n",
    "- keypoints: 18 key points for one human body, 3 dimensions in space\n",
    "- valid_keypoints: ?\n",
    "- projection_error: ?\n",
    "- tag: ?\n",
    "- timestamp: unique identifier for frame, 1 frame every 1 millisecond \n",
    "- keypoint_std_devs = ?\n",
    "\n",
    "Which of these are currently being used / called for the 3D pose tracking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsonify code dana wrote\n",
    "\n",
    "def pose_3d_keypoints_to_list(pose_3d_keypoints):\n",
    "    \"\"\" \n",
    "    convert array to list to write to json\n",
    "    input: 2 dimensional array\n",
    "    output: 2 dimensional list\n",
    "    \"\"\"\n",
    "    keypoints_converted = []\n",
    "    for keypoint_coordinates in pose_3d_keypoints:\n",
    "        keypoints_converted.append(list(keypoint_coordinates))\n",
    "    return keypoints_converted\n",
    "\n",
    "def pose_3d_valid_keypoints_to_string(pose_3d_valid_keypoints):\n",
    "    \"\"\"\n",
    "    convert array of ints to a list of ints to write to json\n",
    "    input: array of ints\n",
    "    output: list of ints\n",
    "    \"\"\"\n",
    "    valid_keypoints_converted = []\n",
    "\n",
    "    for keypoint in pose_3d_valid_keypoints:\n",
    "        keypoint= str(keypoint)\n",
    "        valid_keypoints_converted.append(keypoint)\n",
    "    return valid_keypoints_converted\n",
    "\n",
    "def timestamp_pd_datetime_to_string(timestamp):\n",
    "    \"\"\"\n",
    "    convert a pd datetime to string to write to json\n",
    "    input: pandas datetime object\n",
    "    output: string including year-month-day, hour:minutes:milliseconds\n",
    "    \"\"\"\n",
    "    timestamp_datetime = cv_datetime_utils.convert_to_native_utc_naive(pose_3d_object.timestamp)\n",
    "    timestamp_string = timestamp_datetime.strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "    return timestamp_string\n",
    "\n",
    "def pose_3d_to_dict(pose_3d_object):\n",
    "    \"\"\"convert a 3d pose object to a python dictionary\n",
    "        input: 3d pose object\n",
    "        output: python dictionary\n",
    "    \"\"\"\n",
    "    # convert data to objects that are writable to json\n",
    "    keypoints = pose_3d_keypoints_to_list(pose_3d_object.keypoints)\n",
    "    valid_keypoints = pose_3d_valid_keypoints_to_string(pose_3d_object.valid_keypoints)\n",
    "    timestamp = timestamp_pd_datetime_to_string(pose_3d_object.timestamp)\n",
    "\n",
    "    pose_3d_dict = {\n",
    "        \"keypoints\": keypoints,\n",
    "        \"valid_keypoints\": valid_keypoints,\n",
    "        \"projection_error\": pose_3d_object.projection_error,\n",
    "        \"tag\": pose_3d_object.tag,\n",
    "        \"timestamp\": timestamp_string,\n",
    "        \"keypoint_std_devs\": pose_3d_object.keypoint_std_devs\n",
    "    }\n",
    "    return pose_3d_dict\n",
    "\n",
    "def write_pose_3d_to_json(pose_3d_object):\n",
    "    \"\"\"\n",
    "    write a pose 3d object to json\n",
    "    input: pose_3d_object\n",
    "    output: None\n",
    "    \"\"\"\n",
    "    pose_3d_dict = pose_3d_to_dict(pose_3d_object)\n",
    "    \n",
    "    with open('3d_pose.json', 'w') as json_file:\n",
    "        json_file.write(simplejson.dumps(pose_3d_dict, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json dict for 1 3D pose object\n",
    "pose_3d_object = initial_poses_3d.pose_3d_list_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pose_3d_to_json(pose_3d_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D poses object\n",
    "\n",
    "attributes of a 3D poses object:\n",
    "\n",
    "- pose_3d_list_list: a list of the \"best match\" 3d poses for a given timestamp, in the form of 3d pose objects\n",
    "- num_cameras_source_images: number of cameras for a given timestamp\n",
    "- num_2d_poses_source_images: a list, for each camera, number of poses that were captured\n",
    "- source_cameras: list of dictionaries, one dictionary per camera with camera meta data- source_images: ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsonify code dana wrote\n",
    "\n",
    "def source_cameras_data_to_lists(source_cameras):\n",
    "    \"\"\"\n",
    "    convert np arrays of camera calibration data to json writeable lists\n",
    "    input: a 3d Poses object\n",
    "    output: writable camera calibration data - \n",
    "    (a list of dictionaries with each key mapping to lists instead of np arrays)\"\"\"\n",
    "    source_cameras_json_writeable = []\n",
    "    for camera in source_cameras:\n",
    "        camera_converted = {}\n",
    "        camera_converted['camera_matrix'] = camera['camera_matrix'].tolist()\n",
    "        camera_converted['distortion_coefficients'] = camera['distortion_coefficients'].tolist()\n",
    "        camera_converted['rotation_vector'] = camera['rotation_vector'].tolist()\n",
    "        camera_converted['translation_vector'] = camera['translation_vector'].tolist()\n",
    "        source_cameras_json_writeable.append(camera_converted)\n",
    "    \n",
    "    return source_cameras_json_writeable \n",
    "\n",
    "def poses_3d_to_dict(poses_3d_object):\n",
    "    \"\"\"convert a 3d poses object to a python dictionary\n",
    "        input: 3d pose object\n",
    "        output: python dictionary\n",
    "    \"\"\"\n",
    "    poses_3d = []\n",
    "    for pose_collection in poses_3d_object.pose_3d_list_list:\n",
    "        for pose_3d in pose_collection:\n",
    "            pose_3d_dict = pose_3d_to_dict(pose_3d)\n",
    "            poses_3d.append(pose_3d_dict)\n",
    "            \n",
    "    source_cameras = source_cameras_data_to_lists(poses_3d_object.source_cameras)\n",
    "    \n",
    "    poses_3d_dict = {\n",
    "        \"pose_3d_list_list\": poses_3d,\n",
    "        \"num_cameras_source_images\": poses_3d_object.num_cameras_source_images,\n",
    "        \"num_2d_poses_source_images\": poses_3d_object.num_2d_poses_source_images,\n",
    "        \"source_cameras\": source_cameras,\n",
    "        \"source_images\": poses_3d_object.source_images\n",
    "    }\n",
    "    return poses_3d_dict\n",
    "\n",
    "def write_poses_3d_to_json(poses_3d_object):\n",
    "    \"\"\"\n",
    "    write a poses 3d object to json\n",
    "    input: poses_3d_object\n",
    "    output: None\n",
    "    \"\"\"\n",
    "    \n",
    "    poses_3d_dict = poses_3d_to_dict(poses_3d_object)\n",
    "    \n",
    "    with open('3d_poses.json', 'w') as json_file:\n",
    "        json_file.write(simplejson.dumps(poses_3d_dict, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_poses_3d_to_json(initial_poses_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<pose_tracking_3d.core.Pose3D at 0x12b79bed0>,\n",
       "  <pose_tracking_3d.core.Pose3D at 0x12b6fae90>,\n",
       "  <pose_tracking_3d.core.Pose3D at 0x12bdd4f90>]]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_poses_3d.pose_3d_list_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json dict for 1 3D poses object\n",
    "poses_3d_object = initial_poses_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pose_3d_list_list': [{'keypoints': [[3.254598617553711,\n",
       "     1.168303370475769,\n",
       "     1.4924794435501099],\n",
       "    [3.356855630874634, 0.9134044647216797, 1.3636484146118164],\n",
       "    [3.5265567302703857, 1.0338704586029053, 1.3853520154953003],\n",
       "    [3.7678744792938232, 0.8904278874397278, 1.1950708627700806],\n",
       "    [nan, nan, nan],\n",
       "    [3.206874370574951, 0.856023371219635, 1.3625627756118774],\n",
       "    [nan, nan, nan],\n",
       "    [nan, nan, nan],\n",
       "    [3.4976155757904053, 0.9732094407081604, 0.878951907157898],\n",
       "    [nan, nan, nan],\n",
       "    [nan, nan, nan],\n",
       "    [3.322049140930176, 0.8554972410202026, 0.866292417049408],\n",
       "    [nan, nan, nan],\n",
       "    [nan, nan, nan],\n",
       "    [3.2757222652435303, 1.2216941118240356, 1.5253654718399048],\n",
       "    [nan, nan, nan],\n",
       "    [3.3557536602020264, 1.1372450590133667, 1.517604112625122],\n",
       "    [nan, nan, nan]],\n",
       "   'valid_keypoints': ['True',\n",
       "    'True',\n",
       "    'True',\n",
       "    'True',\n",
       "    'False',\n",
       "    'True',\n",
       "    'False',\n",
       "    'False',\n",
       "    'True',\n",
       "    'False',\n",
       "    'False',\n",
       "    'True',\n",
       "    'False',\n",
       "    'False',\n",
       "    'True',\n",
       "    'False',\n",
       "    'True',\n",
       "    'False'],\n",
       "   'projection_error': 2.7661635080973306,\n",
       "   'tag': None,\n",
       "   'timestamp': '18-20-00',\n",
       "   'keypoint_std_devs': None},\n",
       "  {'keypoints': [[3.254598617553711, 1.168303370475769, 1.4924794435501099],\n",
       "    [3.356855630874634, 0.9134044647216797, 1.3636484146118164],\n",
       "    [3.5265567302703857, 1.0338704586029053, 1.3853520154953003],\n",
       "    [3.7678744792938232, 0.8904278874397278, 1.1950708627700806],\n",
       "    [nan, nan, nan],\n",
       "    [3.206874370574951, 0.856023371219635, 1.3625627756118774],\n",
       "    [nan, nan, nan],\n",
       "    [nan, nan, nan],\n",
       "    [3.4976155757904053, 0.9732094407081604, 0.878951907157898],\n",
       "    [nan, nan, nan],\n",
       "    [nan, nan, nan],\n",
       "    [3.322049140930176, 0.8554972410202026, 0.866292417049408],\n",
       "    [nan, nan, nan],\n",
       "    [nan, nan, nan],\n",
       "    [3.2757222652435303, 1.2216941118240356, 1.5253654718399048],\n",
       "    [nan, nan, nan],\n",
       "    [3.3557536602020264, 1.1372450590133667, 1.517604112625122],\n",
       "    [nan, nan, nan]],\n",
       "   'valid_keypoints': ['True',\n",
       "    'True',\n",
       "    'True',\n",
       "    'True',\n",
       "    'False',\n",
       "    'True',\n",
       "    'False',\n",
       "    'False',\n",
       "    'True',\n",
       "    'False',\n",
       "    'False',\n",
       "    'True',\n",
       "    'False',\n",
       "    'False',\n",
       "    'True',\n",
       "    'False',\n",
       "    'True',\n",
       "    'False'],\n",
       "   'projection_error': 5.295217037200928,\n",
       "   'tag': None,\n",
       "   'timestamp': '18-20-00',\n",
       "   'keypoint_std_devs': None},\n",
       "  {'keypoints': [[3.254598617553711, 1.168303370475769, 1.4924794435501099],\n",
       "    [3.356855630874634, 0.9134044647216797, 1.3636484146118164],\n",
       "    [3.5265567302703857, 1.0338704586029053, 1.3853520154953003],\n",
       "    [3.7678744792938232, 0.8904278874397278, 1.1950708627700806],\n",
       "    [nan, nan, nan],\n",
       "    [3.206874370574951, 0.856023371219635, 1.3625627756118774],\n",
       "    [nan, nan, nan],\n",
       "    [nan, nan, nan],\n",
       "    [3.4976155757904053, 0.9732094407081604, 0.878951907157898],\n",
       "    [nan, nan, nan],\n",
       "    [nan, nan, nan],\n",
       "    [3.322049140930176, 0.8554972410202026, 0.866292417049408],\n",
       "    [nan, nan, nan],\n",
       "    [nan, nan, nan],\n",
       "    [3.2757222652435303, 1.2216941118240356, 1.5253654718399048],\n",
       "    [nan, nan, nan],\n",
       "    [3.3557536602020264, 1.1372450590133667, 1.517604112625122],\n",
       "    [nan, nan, nan]],\n",
       "   'valid_keypoints': ['True',\n",
       "    'True',\n",
       "    'True',\n",
       "    'True',\n",
       "    'False',\n",
       "    'True',\n",
       "    'False',\n",
       "    'False',\n",
       "    'True',\n",
       "    'False',\n",
       "    'False',\n",
       "    'True',\n",
       "    'False',\n",
       "    'False',\n",
       "    'True',\n",
       "    'False',\n",
       "    'True',\n",
       "    'False'],\n",
       "   'projection_error': 4.14439771548725,\n",
       "   'tag': None,\n",
       "   'timestamp': '18-20-00',\n",
       "   'keypoint_std_devs': None}],\n",
       " 'num_cameras_source_images': 4,\n",
       " 'num_2d_poses_source_images': [3, 3, 4, 4],\n",
       " 'source_cameras': [{'camera_matrix': array([[937.94341387,   0.        , 725.34424359],\n",
       "          [  0.        , 958.78641438, 505.9760884 ],\n",
       "          [  0.        ,   0.        ,   1.        ]]),\n",
       "   'distortion_coefficients': array([[ 0.09817407, -0.1101598 ,  0.00219086,  0.00162422, -0.0051582 ]]),\n",
       "   'rotation_vector': array([[ 1.94735706],\n",
       "          [-0.88869177],\n",
       "          [ 0.57001143]]),\n",
       "   'translation_vector': array([[-0.04542804],\n",
       "          [ 2.03880442],\n",
       "          [ 0.50761027]])},\n",
       "  {'camera_matrix': array([[937.94341387,   0.        , 725.34424359],\n",
       "          [  0.        , 958.78641438, 505.9760884 ],\n",
       "          [  0.        ,   0.        ,   1.        ]]),\n",
       "   'distortion_coefficients': array([[ 0.09817407, -0.1101598 ,  0.00219086,  0.00162422, -0.0051582 ]]),\n",
       "   'rotation_vector': array([[ 0.7646155 ],\n",
       "          [-2.39670604],\n",
       "          [ 1.37757928]]),\n",
       "   'translation_vector': array([[ 4.43593037],\n",
       "          [-1.23227748],\n",
       "          [ 6.25302759]])},\n",
       "  {'camera_matrix': array([[937.94341387,   0.        , 725.34424359],\n",
       "          [  0.        , 958.78641438, 505.9760884 ],\n",
       "          [  0.        ,   0.        ,   1.        ]]),\n",
       "   'distortion_coefficients': array([[ 0.09817407, -0.1101598 ,  0.00219086,  0.00162422, -0.0051582 ]]),\n",
       "   'rotation_vector': array([[ 0.83618383],\n",
       "          [ 2.22358289],\n",
       "          [-1.35058963]]),\n",
       "   'translation_vector': array([[-0.51701819],\n",
       "          [-2.5645926 ],\n",
       "          [ 9.55193924]])},\n",
       "  {'camera_matrix': array([[937.94341387,   0.        , 725.34424359],\n",
       "          [  0.        , 958.78641438, 505.9760884 ],\n",
       "          [  0.        ,   0.        ,   1.        ]]),\n",
       "   'distortion_coefficients': array([[ 0.09817407, -0.1101598 ,  0.00219086,  0.00162422, -0.0051582 ]]),\n",
       "   'rotation_vector': array([[ 1.94188985],\n",
       "          [ 0.73110533],\n",
       "          [-0.38780331]]),\n",
       "   'translation_vector': array([[-5.14088877],\n",
       "          [-0.07528158],\n",
       "          [ 4.10267338]])}],\n",
       " 'source_images': None}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses_3d_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "currently, we are generating a Poses3D object for each timestamp, which includes Pose3D objects for each camera\n",
    "\n",
    "Could output to 1 json file per timestamp:\n",
    "\n",
    "2018-07-04_18-20-00-000.json\n",
    "\n",
    "{\n",
    "    \"camera01\": [\n",
    "        \"Pose3D object 1\",\n",
    "        Pose3d object 2\n",
    "        ]\n",
    "    \"camera02\": [\n",
    "        \"Pose3D object 1\", \n",
    "        ...\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Pose Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize 3D pose tracking\n",
    "\n",
    "pose_tracks = pose_tracking_3d.Pose3DTracks.initialize(\n",
    "    pose_initialization_model=pose_initialization_model,\n",
    "    keypoint_model=keypoint_model,\n",
    "    pose_tracking_model=pose_tracking_model,\n",
    "    pose_3d_observations=initial_poses_3d,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "for row_index in range(1, num_rows):\n",
    "    dataframe_row = input_dataframe.iloc[row_index]\n",
    "    poses_2d = pose_tracking_3d.Poses2D.from_dataframe_row(dataframe_row, camera_names)\n",
    "    poses_3d = pose_tracking_3d.Poses3D.from_poses_2d(poses_2d, camera_calibration_parameters)\n",
    "    pose_tracks.update(poses_3d)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "\n",
    "print(\n",
    "    \"{} tracks produced from {} frames in {:.1f} seconds: {:.1f} milliseconds per frame\".format(\n",
    "        pose_tracks.num_inactive_tracks() + pose_tracks.num_active_tracks(),\n",
    "        num_rows,\n",
    "        elapsed_time,\n",
    "        1000 * elapsed_time / num_rows,\n",
    "    )\n",
    ")\n",
    "\n",
    "output_dataframe = pose_tracks.dataframe()\n",
    "\n",
    "output_dataframe.to_pickle(output_dataframe_path)\n",
    "\n",
    "print(\"Output saved in {}\".format(output_dataframe_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3d-v2",
   "language": "python",
   "name": "3d-v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
